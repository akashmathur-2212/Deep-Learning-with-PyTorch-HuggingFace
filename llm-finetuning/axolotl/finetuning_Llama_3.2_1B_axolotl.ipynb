{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MPnE8T6VEeG"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# This step can take ~5-10 minutes to install dependencies\n",
    "!pip install torch==\"2.7.2\"\n",
    "!pip install --no-build-isolation axolotl[flash-attn]>=0.9.1\n",
    "!pip install \"cut-cross-entropy[transformers] @ git+https://github.com/axolotl-ai-cloud/ml-cross-entropy.git@c6a32c5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37MH7gh0ucOF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kWCCWsvxMIF"
   },
   "outputs": [],
   "source": [
    "yaml_string = \"\"\"\n",
    "base_model: meta-llama/Llama-3.2-1B\n",
    "model_type: LlamaForCausalLM\n",
    "tokenizer_type: PreTrainedTokenizerFast\n",
    "is_llama_derived_model: true\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: true\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: tayyibsupercool/Evol-Instruct-Code-80k-v1\n",
    "    type: alpaca\n",
    "dataset_prepared_path:\n",
    "val_set_size: 0.05\n",
    "output_dir: ./qlora-out\n",
    "\n",
    "adapter: qlora\n",
    "lora_model_dir:\n",
    "\n",
    "sequence_len: 2048\n",
    "sample_packing: true\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "lora_r: 32\n",
    "lora_alpha: 16\n",
    "lora_dropout: 0.05\n",
    "lora_target_modules:\n",
    "lora_target_linear: true\n",
    "lora_fan_in_fan_out:\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 1\n",
    "micro_batch_size: 1\n",
    "num_epochs: 2\n",
    "max_steps: 20\n",
    "optimizer: paged_adamw_32bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: false\n",
    "fp16: true\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention:\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch:\n",
    "saves_per_epoch:\n",
    "debug:\n",
    "deepspeed:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "special_tokens:\n",
    "    pad_token: \"<eos>\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaPTiKIsw3BX",
    "outputId": "c1c01bf5-53f0-4dbd-c0ec-a9e5633e179b"
   },
   "outputs": [],
   "source": [
    "yaml_config = yaml.safe_load(yaml_string)\n",
    "yaml_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K21I4mcVxhRC"
   },
   "outputs": [],
   "source": [
    "with open(\"config_axolotl.yaml\", \"w\") as f:\n",
    "    yaml.dump(yaml_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLwYpoHPwI8G"
   },
   "outputs": [],
   "source": [
    "!accelerate launch -m axolotl.cli.train /content/config_axolotl.yaml"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
