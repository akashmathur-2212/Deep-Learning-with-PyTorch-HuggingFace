{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# This step can take ~5-10 minutes to install dependencies\n",
        "!pip install torch==\"2.7.2\"\n",
        "!pip install --no-build-isolation axolotl[flash-attn]>=0.9.1\n",
        "!pip install \"cut-cross-entropy[transformers] @ git+https://github.com/axolotl-ai-cloud/ml-cross-entropy.git@c6a32c5\""
      ],
      "metadata": {
        "id": "6MPnE8T6VEeG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import yaml"
      ],
      "metadata": {
        "id": "37MH7gh0ucOF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_string = \"\"\"\n",
        "base_model: meta-llama/Llama-3.2-1B\n",
        "model_type: LlamaForCausalLM\n",
        "tokenizer_type: PreTrainedTokenizerFast\n",
        "is_llama_derived_model: true\n",
        "\n",
        "load_in_8bit: false\n",
        "load_in_4bit: true\n",
        "strict: false\n",
        "\n",
        "datasets:\n",
        "  - path: tayyibsupercool/Evol-Instruct-Code-80k-v1\n",
        "    type: alpaca\n",
        "dataset_prepared_path:\n",
        "val_set_size: 0.05\n",
        "output_dir: ./qlora-out\n",
        "\n",
        "adapter: qlora\n",
        "lora_model_dir:\n",
        "\n",
        "sequence_len: 2048\n",
        "sample_packing: true\n",
        "pad_to_sequence_len: true\n",
        "\n",
        "lora_r: 32\n",
        "lora_alpha: 16\n",
        "lora_dropout: 0.05\n",
        "lora_target_modules:\n",
        "lora_target_linear: true\n",
        "lora_fan_in_fan_out:\n",
        "\n",
        "wandb_project:\n",
        "wandb_entity:\n",
        "wandb_watch:\n",
        "wandb_name:\n",
        "wandb_log_model:\n",
        "\n",
        "gradient_accumulation_steps: 1\n",
        "micro_batch_size: 1\n",
        "num_epochs: 2\n",
        "max_steps: 20\n",
        "optimizer: paged_adamw_32bit\n",
        "lr_scheduler: cosine\n",
        "learning_rate: 0.0002\n",
        "\n",
        "train_on_inputs: false\n",
        "group_by_length: false\n",
        "bf16: false\n",
        "fp16: true\n",
        "tf32: false\n",
        "\n",
        "gradient_checkpointing: true\n",
        "early_stopping_patience:\n",
        "resume_from_checkpoint:\n",
        "local_rank:\n",
        "logging_steps: 1\n",
        "xformers_attention:\n",
        "flash_attention:\n",
        "\n",
        "warmup_steps: 10\n",
        "evals_per_epoch:\n",
        "saves_per_epoch:\n",
        "debug:\n",
        "deepspeed:\n",
        "weight_decay: 0.0\n",
        "fsdp:\n",
        "fsdp_config:\n",
        "special_tokens:\n",
        "    pad_token: \"<eos>\"\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-kWCCWsvxMIF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_config = yaml.safe_load(yaml_string)\n",
        "yaml_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaPTiKIsw3BX",
        "outputId": "c1c01bf5-53f0-4dbd-c0ec-a9e5633e179b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_model': 'meta-llama/Llama-3.2-1B',\n",
              " 'model_type': 'LlamaForCausalLM',\n",
              " 'tokenizer_type': 'PreTrainedTokenizerFast',\n",
              " 'is_llama_derived_model': True,\n",
              " 'load_in_8bit': False,\n",
              " 'load_in_4bit': True,\n",
              " 'strict': False,\n",
              " 'datasets': [{'path': 'tayyibsupercool/Evol-Instruct-Code-80k-v1',\n",
              "   'type': 'alpaca'}],\n",
              " 'dataset_prepared_path': None,\n",
              " 'val_set_size': 0.05,\n",
              " 'output_dir': './qlora-out',\n",
              " 'adapter': 'qlora',\n",
              " 'lora_model_dir': None,\n",
              " 'sequence_len': 2048,\n",
              " 'sample_packing': True,\n",
              " 'pad_to_sequence_len': True,\n",
              " 'lora_r': 32,\n",
              " 'lora_alpha': 16,\n",
              " 'lora_dropout': 0.05,\n",
              " 'lora_target_modules': None,\n",
              " 'lora_target_linear': True,\n",
              " 'lora_fan_in_fan_out': None,\n",
              " 'wandb_project': None,\n",
              " 'wandb_entity': None,\n",
              " 'wandb_watch': None,\n",
              " 'wandb_name': None,\n",
              " 'wandb_log_model': None,\n",
              " 'gradient_accumulation_steps': 1,\n",
              " 'micro_batch_size': 1,\n",
              " 'num_epochs': 2,\n",
              " 'max_steps': 20,\n",
              " 'optimizer': 'paged_adamw_32bit',\n",
              " 'lr_scheduler': 'cosine',\n",
              " 'learning_rate': 0.0002,\n",
              " 'train_on_inputs': False,\n",
              " 'group_by_length': False,\n",
              " 'bf16': False,\n",
              " 'fp16': True,\n",
              " 'tf32': False,\n",
              " 'gradient_checkpointing': True,\n",
              " 'early_stopping_patience': None,\n",
              " 'resume_from_checkpoint': None,\n",
              " 'local_rank': None,\n",
              " 'logging_steps': 1,\n",
              " 'xformers_attention': None,\n",
              " 'flash_attention': None,\n",
              " 'warmup_steps': 10,\n",
              " 'evals_per_epoch': None,\n",
              " 'saves_per_epoch': None,\n",
              " 'debug': None,\n",
              " 'deepspeed': None,\n",
              " 'weight_decay': 0.0,\n",
              " 'fsdp': None,\n",
              " 'fsdp_config': None,\n",
              " 'special_tokens': {'pad_token': '<eos>'}}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"config_axolotl.yaml\", \"w\") as f:\n",
        "    yaml.dump(yaml_config, f)"
      ],
      "metadata": {
        "id": "K21I4mcVxhRC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train /content/config_axolotl.yaml"
      ],
      "metadata": {
        "id": "CLwYpoHPwI8G"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}